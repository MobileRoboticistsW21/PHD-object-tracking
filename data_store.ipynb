{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"data_store.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"cells":[{"cell_type":"markdown","metadata":{"id":"t2WkrKe-2U7H"},"source":["# Setup Code\n","Run one of Block 1 or Block 2 for setup Mask_RCNN_stuff repo."]},{"cell_type":"markdown","metadata":{"id":"olGpo5q_2p7J"},"source":["### Block 1 (If you upload this repo to gDrive)"]},{"cell_type":"code","metadata":{"id":"6wlmVZXt10ax","executionInfo":{"status":"ok","timestamp":1617307493515,"user_tz":240,"elapsed":471,"user":{"displayName":"Heming Huang","photoUrl":"","userId":"00439147638198051252"}}},"source":["%load_ext autoreload\n","%autoreload 2"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y0E_bp_213Mg","executionInfo":{"status":"ok","timestamp":1617307510517,"user_tz":240,"elapsed":14348,"user":{"displayName":"Heming Huang","photoUrl":"","userId":"00439147638198051252"}},"outputId":"25e6f0c8-99e6-46a0-85b0-c758e231a0e8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pw8YhqgO1-M0","executionInfo":{"status":"ok","timestamp":1617307628368,"user_tz":240,"elapsed":219,"user":{"displayName":"Heming Huang","photoUrl":"","userId":"00439147638198051252"}},"outputId":"d4af500f-dde1-47a7-911e-a9fc0ca543f0"},"source":["import os\n","\n","# TODO: Fill in the Google Drive path where you uploaded the assignment\n","# Example: If you create a 2020FA folder and put all the files under \"A3\" folder, then '2020FA/A3'\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '/content/drive/MyDrive/Mask_RCNN_stuff'\n","ROOT_DIR = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(ROOT_DIR))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["['data_store.ipynb', '.git', 'coco.py', 'config.py', 'images', 'shapes.py', 'utils.py', 'visualize.py', '__pycache__', 'MOT16-14-raw.mp4', 'MOT16-11-raw.mp4', 'MOT16-11', 'pickles', 'MOT16-14', 'MOT16-09', 'model.py', 'Mask_RCNN_(1).ipynb', 'maskrcnn_res_16_11.pkl', '.ipynb_checkpoints', 'optical_flow_16-11.pkl', 'Mask_RCNN.ipynb', 'maskrcnn_res_16_09.pkl', 'maskrcnn_res_16_14_frame100.pkl', 'maskrcnn_res_16_14_frame400.pkl']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iaMB0gph4CCv","executionInfo":{"status":"ok","timestamp":1617307657610,"user_tz":240,"elapsed":228,"user":{"displayName":"Heming Huang","photoUrl":"","userId":"00439147638198051252"}}},"source":["import sys\n","sys.path.append(ROOT_DIR)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ExlLZfya2sEi"},"source":["### Block 2 (If you want to clone repo to CoLab's temporary storage)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A7sq2ebxDpgM","executionInfo":{"status":"ok","timestamp":1617307660813,"user_tz":240,"elapsed":1662,"user":{"displayName":"Heming Huang","photoUrl":"","userId":"00439147638198051252"}},"outputId":"738d6d96-1a35-44dc-c5aa-f164b9603417"},"source":["!git clone https://github.com/MobileRoboticistsW21/Mask_RCNN_stuff.git\n","%cd Mask_RCNN_stuff/"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Cloning into 'Mask_RCNN_stuff'...\n","remote: Enumerating objects: 46, done.\u001b[K\n","remote: Counting objects: 100% (46/46), done.\u001b[K\n","remote: Compressing objects: 100% (45/45), done.\u001b[K\n","remote: Total 46 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (46/46), done.\n","/content/Mask_RCNN_stuff\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PhdzE_izpXzz"},"source":["# import os\n","# # Root directory of the project\n","# ROOT_DIR = os.getcwd()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"35jmH-1E2wo1"},"source":["# Install packages & Download weights"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"szVLu-UCN-rF","executionInfo":{"status":"ok","timestamp":1617307722979,"user_tz":240,"elapsed":59939,"user":{"displayName":"Heming Huang","photoUrl":"","userId":"00439147638198051252"}},"outputId":"82f237f1-add1-4248-b008-638491e539c0"},"source":["# the following version can run the thing, even though not the best ones\n","!pip install tensorflow==1.13.1\n","!pip install keras==2.0.8\n","!pip install scipy==1.2.1"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.13.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/29/6b4f1e02417c3a1ccc85380f093556ffd0b35dc354078074c5195c8447f2/tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6MB)\n","\u001b[K     |████████████████████████████████| 92.6MB 45kB/s \n","\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 37.5MB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.32.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.36.2)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.3.3)\n","Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n","\u001b[K     |████████████████████████████████| 368kB 51.9MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n","Collecting keras-applications>=1.0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.12.4)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.12.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.4)\n","Collecting mock>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (54.2.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.1)\n","Installing collected packages: tensorboard, mock, tensorflow-estimator, keras-applications, tensorflow\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: tensorflow 2.4.1\n","    Uninstalling tensorflow-2.4.1:\n","      Successfully uninstalled tensorflow-2.4.1\n","Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n","Collecting keras==2.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/3f/d117d6e48b19fb9589369f4bdbe883aa88943f8bb4a850559ea5c546fefb/Keras-2.0.8-py2.py3-none-any.whl (276kB)\n","\u001b[K     |████████████████████████████████| 276kB 21.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.19.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.4.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.15.0)\n","\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 2.0.8 which is incompatible.\u001b[0m\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.4.3\n","    Uninstalling Keras-2.4.3:\n","      Successfully uninstalled Keras-2.4.3\n","Successfully installed keras-2.0.8\n","Collecting scipy==1.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/7e/5cee36eee5b3194687232f6150a89a38f784883c612db7f4da2ab190980d/scipy-1.2.1-cp37-cp37m-manylinux1_x86_64.whl (24.8MB)\n","\u001b[K     |████████████████████████████████| 24.8MB 131kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.2.1) (1.19.5)\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: scipy\n","  Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","Successfully installed scipy-1.2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_YyTSFypEAGq","executionInfo":{"status":"ok","timestamp":1617307735470,"user_tz":240,"elapsed":5076,"user":{"displayName":"Heming Huang","photoUrl":"","userId":"00439147638198051252"}},"outputId":"52d0bc94-1b96-4230-b12e-7485a98c48ec"},"source":["# download weights\n","!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5"],"execution_count":7,"outputs":[{"output_type":"stream","text":["--2021-04-01 20:08:50--  https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n","Resolving github.com (github.com)... 140.82.114.4\n","Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://github-releases.githubusercontent.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210401%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210401T200850Z&X-Amz-Expires=300&X-Amz-Signature=a550be0aae909255cde07bc805164b22e880711ee7c60b452fed1ef5829af328&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=107595270&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream [following]\n","--2021-04-01 20:08:50--  https://github-releases.githubusercontent.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210401%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210401T200850Z&X-Amz-Expires=300&X-Amz-Signature=a550be0aae909255cde07bc805164b22e880711ee7c60b452fed1ef5829af328&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=107595270&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream\n","Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.110.154, 185.199.109.154, 185.199.111.154, ...\n","Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.110.154|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 257557808 (246M) [application/octet-stream]\n","Saving to: ‘mask_rcnn_coco.h5’\n","\n","mask_rcnn_coco.h5   100%[===================>] 245.63M  53.2MB/s    in 4.5s    \n","\n","2021-04-01 20:08:55 (54.2 MB/s) - ‘mask_rcnn_coco.h5’ saved [257557808/257557808]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZQiyPZTXG_he"},"source":["# Mask R-CNN Demo\n","\n","A quick intro to using the pre-trained model to detect and segment objects."]},{"cell_type":"code","metadata":{"id":"Jb_v0BM6G_hm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617307740657,"user_tz":240,"elapsed":3044,"user":{"displayName":"Heming Huang","photoUrl":"","userId":"00439147638198051252"}},"outputId":"e50615ff-912c-4cd6-d49b-5e6068ed1505"},"source":["import sys\n","import random\n","import math\n","import numpy as np\n","import scipy.misc\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","import coco\n","import utils\n","import model as modellib\n","import visualize\n","\n","%matplotlib inline \n","\n","# Directory to save logs and trained model\n","MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n","\n","# Path to trained weights file\n","# Download this file and place in the root of your \n","# project (See README file for details)\n","COCO_MODEL_PATH = os.path.join(os.getcwd(), \"mask_rcnn_coco.h5\")\n","\n","# Directory of images(frames) to run detection on\n","IMAGE_DIR = os.path.join(ROOT_DIR, \"MOT16-14\")\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"syp1OoTdV1Re","executionInfo":{"status":"ok","timestamp":1617307742420,"user_tz":240,"elapsed":224,"user":{"displayName":"Heming Huang","photoUrl":"","userId":"00439147638198051252"}},"outputId":"f5c28571-528e-4c28-8ec9-a067bbd37571"},"source":["print(IMAGE_DIR)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Mask_RCNN_stuff/MOT16-14\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MfZmWYIlG_hn"},"source":["## Configurations (TODO!!!)\n","\n","We'll be using a model trained on the MS-COCO dataset. The configurations of this model are in the ```CocoConfig``` class in ```coco.py```.\n","\n","For inferencing, modify the configurations a bit to fit the task. To do so, sub-class the ```CocoConfig``` class and override the attributes you need to change."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VTydeU7bG_ho","executionInfo":{"status":"ok","timestamp":1617307752716,"user_tz":240,"elapsed":215,"user":{"displayName":"Heming Huang","photoUrl":"","userId":"00439147638198051252"}},"outputId":"82f3bb95-fac0-4591-9d56-d1f509ca7bb4"},"source":["class InferenceConfig(coco.CocoConfig):\n","    # Set batch size to 1 since we'll be running inference on\n","    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","\n","config = InferenceConfig()\n","config.print()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["\n","Configurations:\n","BACKBONE_SHAPES                [[256 256]\n"," [128 128]\n"," [ 64  64]\n"," [ 32  32]\n"," [ 16  16]]\n","BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n","BATCH_SIZE                     1\n","BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n","DETECTION_MAX_INSTANCES        100\n","DETECTION_MIN_CONFIDENCE       0.7\n","DETECTION_NMS_THRESHOLD        0.3\n","GPU_COUNT                      1\n","IMAGES_PER_GPU                 1\n","IMAGE_MAX_DIM                  1024\n","IMAGE_MIN_DIM                  800\n","IMAGE_PADDING                  True\n","IMAGE_SHAPE                    [1024 1024    3]\n","LEARNING_MOMENTUM              0.9\n","LEARNING_RATE                  0.002\n","MASK_POOL_SIZE                 14\n","MASK_SHAPE                     [28, 28]\n","MAX_GT_INSTANCES               100\n","MEAN_PIXEL                     [123.7 116.8 103.9]\n","MINI_MASK_SHAPE                (56, 56)\n","NAME                           coco\n","NUM_CLASSES                    81\n","POOL_SIZE                      7\n","POST_NMS_ROIS_INFERENCE        1000\n","POST_NMS_ROIS_TRAINING         2000\n","ROI_POSITIVE_RATIO             0.33\n","RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n","RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n","RPN_ANCHOR_STRIDE              2\n","RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n","RPN_TRAIN_ANCHORS_PER_IMAGE    256\n","STEPS_PER_EPOCH                1000\n","TRAIN_ROIS_PER_IMAGE           128\n","USE_MINI_MASK                  True\n","USE_RPN_ROIS                   True\n","VALIDATION_STPES               50\n","WEIGHT_DECAY                   0.0001\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rpgAMvxUG_ho"},"source":["## Create Model and Load Trained Weights"]},{"cell_type":"code","metadata":{"id":"xoHy4xarG_hp","scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617307762301,"user_tz":240,"elapsed":7152,"user":{"displayName":"Heming Huang","photoUrl":"","userId":"00439147638198051252"}},"outputId":"832a70a7-9ebf-43b0-b9ec-9d0d0443dab2"},"source":["# Create model object in inference mode.\n","model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n","\n","# Load weights trained on MS-COCO\n","model.load_weights(COCO_MODEL_PATH, by_name=True)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2888: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/Mask_RCNN_stuff/model.py:736: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, use\n","    tf.py_function, which takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g__9tTDgG_hp"},"source":["## Class Names\n","\n","The model classifies objects and returns class IDs, which are integer value that identify each class. Some datasets assign integer values to their classes and some don't. For example, in the MS-COCO dataset, the 'person' class is 1 and 'teddy bear' is 88. The IDs are often sequential, but not always. The COCO dataset, for example, has classes associated with class IDs 70 and 72, but not 71.\n","\n","To improve consistency, and to support training on data from multiple sources at the same time, our ```Dataset``` class assigns it's own sequential integer IDs to each class. For example, if you load the COCO dataset using our ```Dataset``` class, the 'person' class would get class ID = 1 (just like COCO) and the 'teddy bear' class is 78 (different from COCO). Keep that in mind when mapping class IDs to class names.\n","\n","To get the list of class names, you'd load the dataset and then use the ```class_names``` property like this.\n","```\n","# Load COCO dataset\n","dataset = coco.CocoDataset()\n","dataset.load_coco(COCO_DIR, \"train\")\n","dataset.prepare()\n","\n","# Print class names\n","print(dataset.class_names)\n","```\n","\n","We don't want to require you to download the COCO dataset just to run this demo, so we're including the list of class names below. The index of the class name in the list represent its ID (first class is 0, second is 1, third is 2, ...etc.)"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"w6GEU3WEG_hq"},"source":["# COCO Class names\n","# Index of the class in the list is its ID. For example, to get ID of\n","# the teddy bear class, use: class_names.index('teddy bear')\n","class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n","               'bus', 'train', 'truck', 'boat', 'traffic light',\n","               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n","               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n","               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n","               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n","               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n","               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n","               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n","               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n","               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n","               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n","               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n","               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n","               'teddy bear', 'hair drier', 'toothbrush']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"koNsqTgdG_hq"},"source":["## Run Object Detection (DONT RUN HERE!!!)"]},{"cell_type":"code","metadata":{"id":"AmDDebXRG_hq","scrolled":false},"source":["import pickle\n","\n","# Load a random image from the images folder\n","file_names = next(os.walk(IMAGE_DIR))[2]\n","file_names.sort()\n","\n","# select a part of frames\n","file_names = file_names[0:5]\n","\n","images = []\n","\n","# Run detection\n","results = []\n","for i, file_name in enumerate(file_names):\n","    image = scipy.misc.imread(os.path.join(IMAGE_DIR, file_name))\n","    result = model.detect([image], verbose=0)\n","    r = result[0]\n","\n","    # only keep person, cicycle, car, motorcycle, bus, and truck\n","    idx_to_keep = np.concatenate([np.where(r['class_ids'] == 1)[0], \\\n","                          np.where(r['class_ids'] == 2)[0], \\\n","                          np.where(r['class_ids'] == 3)[0], \\\n","                          np.where(r['class_ids'] == 4)[0], \\\n","                          np.where(r['class_ids'] == 6)[0], \\\n","                          np.where(r['class_ids'] == 8)[0]])\n","\n","    # these are the needed info for optical flow? \n","    # maybe image as well?\n","    r['rois'] = r['rois'][idx_to_keep]\n","    r['masks'] = r['masks'][:,:, idx_to_keep]\n","    r['class_ids'] = r['class_ids'][idx_to_keep]\n","    r['scores'] = r['scores'][idx_to_keep]\n","    results.append(r)\n","    if i % 50 == 0:\n","        print(\"saving result @ \" + str(i))\n","        pickle.dump(results, open('/content/drive/MyDrive/EECS 568/Final Projects/Mask_RCNN_stuff/maskrcnn_res_' + str(i) + '.pkl', 'wb'))\n","\n","\n","pickle.dump(results, open('/content/drive/MyDrive/EECS 568/Final Projects/Mask_RCNN_stuff/maskrcnn_res_16_11_first5.pkl', 'wb'))\n","\n","for i, file_name in enumerate(file_names[:5]):\n","    image = scipy.misc.imread(os.path.join(IMAGE_DIR, file_name))\n","    visualize.display_instances(image, results[i]['rois'], results[i]['masks'], results[i]['class_ids'], \n","                                class_names, results[i]['scores'])\n","# dump with pickle\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5XXpWHW7mSJ9"},"source":["# Optical Flow"]},{"cell_type":"code","metadata":{"id":"ca7XP3EQnHc4","executionInfo":{"status":"ok","timestamp":1617307823040,"user_tz":240,"elapsed":4994,"user":{"displayName":"Heming Huang","photoUrl":"","userId":"00439147638198051252"}}},"source":["import pickle\n","PICKLE_DIR = os.path.join(ROOT_DIR, \"maskrcnn_res_16_14_frame100.pkl\")\n","load_res = pickle.load(open(PICKLE_DIR, 'rb'))\n","\n","IMAGE_DIR = os.path.join(ROOT_DIR, \"MOT16-14\")"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ohr_IpSImRB-","executionInfo":{"status":"ok","timestamp":1617307831186,"user_tz":240,"elapsed":5894,"user":{"displayName":"Heming Huang","photoUrl":"","userId":"00439147638198051252"}},"outputId":"b5e8e7b6-7331-4ea3-9816-302b8d9daa90"},"source":["import numpy as np\n","import cv2\n","import cv2 as cv\n","from google.colab.patches import cv2_imshow\n","\n","file_names = os.listdir(IMAGE_DIR)\n","#file_names = next(os.walk(IMAGE_DIR))[2]\n","file_names.sort()\n","begin_idx = 0\n","end_idx = 10\n","\n","# list to store optical flow results\n","results = [] # a list of #frame dictionaries, \n","             # each dictionary has two keys \"bb\" and \"flows\"\n","             # their values are a list of data for each detected object\n","\n","# Take first frame and find corners in it\n","frame1 = cv2.imread(os.path.join(IMAGE_DIR, file_names[begin_idx]))\n","begin_idx += 1\n","\n","prvs = cv.cvtColor(frame1,cv.COLOR_BGR2GRAY) #convert to grayscale\n","hsv = np.zeros_like(frame1)\n","hsv[...,1] = 255\n","while(begin_idx < end_idx):\n","    print(\"working on frame #\", begin_idx - 1)\n","    frame2 = cv2.imread(os.path.join(IMAGE_DIR, file_names[begin_idx]))\n","    begin_idx += 1\n","    next = cv.cvtColor(frame2,cv.COLOR_BGR2GRAY)\n","    flow = cv.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 25, 3, 5, 1.2, 0) # https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af\n","\n","    mag, ang = cv.cartToPolar(flow[...,0], flow[...,1])\n","    hsv[...,0] = ang*180/np.pi/2\n","    hsv[...,2] = cv.normalize(mag,None,0,255,cv.NORM_MINMAX)\n","    bgr = cv.cvtColor(hsv,cv.COLOR_HSV2BGR)\n","\n","    # visualize.display_instances(bgr, load_res[begin_idx]['rois'], load_res[begin_idx]['masks'], load_res[begin_idx]['class_ids'], \n","    #                             class_names, load_res[begin_idx]['scores'])\n","    # k = cv.waitKey(30) & 0xff\n","    # if k == 27:\n","    #     break\n","    # elif k == ord('s'):\n","    #     cv.imwrite('opticalfb.png',frame2)\n","    #     cv.imwrite('opticalhsv.png',bgr)\n","    prvs = next\n","\n","    # create a new dictionary to store results in this frame\n","    res_dict = {}\n","\n","    # Calculates bounding boxes' centers and widths & heights in 1st frame\n","    bb_info = []\n","    list_of_bb = load_res[begin_idx - 1]['rois']\n","    for bb in list_of_bb:\n","      bb_x = (bb[0] + bb[2]) / 2.0 \n","      bb_y = (bb[1] + bb[3]) / 2.0 \n","      bb_info.append([bb_x, bb_y, int(abs(bb[2]-bb[0])), int(abs(bb[3]-bb[1]))])\n","\n","    res_dict['bb'] = bb_info\n","\n","    # Appying masks to get averaged flow from 1st to 2nd frame for each detected object\n","    velocities = []\n","    for obj_idx in range(load_res[begin_idx]['masks'].shape[2]):\n","      mask = load_res[begin_idx]['masks'][:,:,obj_idx]\n","      num_pixels = np.sum(mask)\n","      \n","      # use mask to filter out pixel values that doesn't belong to this object\n","      flow_mask_x = np.where(mask, flow[:,:,0], 0)\n","      flow_mask_y = np.where(mask, flow[:,:,1], 0)\n","\n","      # calculate average velocities in x and y.\n","      avg_x_vel = np.sum(flow_mask_x) / num_pixels\n","      avg_y_vel = np.sum(flow_mask_y) / num_pixels\n","      # print(\"avgs: \", avg_x_vel, avg_y_vel)\n","      velocities.append([avg_x_vel, avg_y_vel])\n","    res_dict['flows'] = velocities\n","\n","    # Push current frame's dictionary into results\n","    results.append(res_dict)\n","  \n","print(results)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["working on frame # 0\n","working on frame # 1\n","working on frame # 2\n","working on frame # 3\n","working on frame # 4\n","working on frame # 5\n","working on frame # 6\n","working on frame # 7\n","working on frame # 8\n","[{'bb': [[307.5, 688.0, 61, 26], [288.0, 88.5, 92, 31], [248.5, 95.0, 73, 28], [302.0, 214.0, 86, 54], [309.5, 589.0, 53, 58], [297.0, 747.5, 40, 55], [460.0, 91.0, 156, 182], [346.5, 921.5, 91, 77], [269.5, 553.0, 31, 36], [258.5, 486.5, 117, 77]], 'flows': [[2.0214577414772728, 1.5949044363839286], [-3.932153493872186, -0.5822724979635664], [-1.9213989741578599, -0.8468419910264614], [-0.0504164237324868, 0.33737744710944517], [3.278681707889793, 1.9474924908030682], [-11.98357075603292, 5.050427985655833], [12.70269645323599, 5.085253572250723], [0.021398871022628215, 0.26175692458204536], [0.1481339383832934, 0.11966493947771105]]}, {'bb': [[307.0, 690.0, 62, 30], [291.5, 80.5, 73, 29], [246.0, 93.5, 66, 25], [308.0, 589.5, 52, 59], [295.5, 750.0, 39, 58], [460.0, 90.0, 152, 180], [344.5, 928.0, 81, 64], [269.0, 553.5, 32, 35], [259.0, 486.0, 120, 78]], 'flows': [[-4.051504841066862, 1.0561733057693186], [2.5964639066445705, -0.20282993894634824], [-3.6857505331234055, 0.7087743330974968], [6.2249938414977475, -1.2258752771326014], [-1.9162903581848894, 0.15083342043714967], [0.46818280460858586, -1.1160282341073782], [14.809179800201962, 2.0019921480543132], [-11.650136466408268, 8.007128552971576], [4.1147528951139005, -0.2089065666885066], [0.4810958584872159, -0.9446853545217803], [0.49424933473747223, -0.7964255599521084]]}, {'bb': [[300.0, 204.5, 94, 57], [308.5, 691.0, 65, 28], [287.0, 78.0, 68, 26], [264.0, 847.0, 78, 22], [254.0, 91.0, 74, 24], [308.5, 590.5, 51, 57], [351.0, 934.0, 92, 52], [462.0, 83.0, 148, 166], [297.5, 753.5, 39, 59], [269.5, 554.0, 31, 36], [259.0, 486.5, 118, 77]], 'flows': [[-4.387256660846749, -0.2846940743802774], [2.1257683079527006, 1.4341752774037042], [5.656258370535714, 1.4307064964657739], [-4.711942911052894, 0.6602771507765719], [-0.0757986554679684, 0.33677090534161014], [3.6149912081552706, 2.007982911547365], [12.140985223702877, 4.181107810599919], [-12.25285830630278, 5.615796795481237], [-0.05215171786421903, 0.5036980253694721], [0.15103766334687208, 0.40827789806460574]]}, {'bb': [[290.0, 71.5, 68, 21], [310.0, 692.0, 66, 28], [262.0, 848.5, 82, 23], [303.0, 202.0, 98, 56], [306.0, 589.0, 54, 58], [299.0, 758.0, 40, 64], [350.0, 939.5, 84, 41], [461.5, 82.5, 143, 165], [268.5, 554.0, 31, 36], [258.0, 486.0, 122, 78]], 'flows': [[2.4067941322197055, 0.06261486429320322], [-4.724753285909327, 0.9964753678701457], [-4.8691872989430145, 0.6630853391161152], [0.06919943502910607, -0.8220978054229574], [3.968457138919515, 0.6239012998940532], [-12.225785981474884, 6.987431903871274], [12.97174765338828, 3.1660928318643164], [0.17601738928614558, -0.6346503766906956], [0.15610787111875218, -0.5590003763964855]]}, {'bb': [[311.5, 696.0, 69, 30], [302.5, 196.0, 93, 58], [294.5, 67.5, 71, 21], [305.5, 589.0, 53, 58], [299.5, 764.0, 45, 60], [466.0, 78.0, 136, 156], [360.0, 945.0, 90, 28], [268.5, 554.5, 31, 37], [258.0, 486.5, 122, 79]], 'flows': [[-4.6449399113456735, -0.14893914855855475], [-4.476184425451566, 0.4267077433788563], [2.5594719190076947, 0.7092740970483087], [0.10069120555053968, -0.08212183506483801], [-4.092500139953224, -0.32176009257128285], [0.5930343585267649, -0.1842749632082581], [4.417265365779735, 1.5769157623867407], [-12.197372586938664, 6.5413215361445785], [0.29955266674919306, -0.05874922577763947], [0.5808629847284573, -0.16726768550588123]]}, {'bb': [[303.5, 60.0, 83, 24], [305.0, 192.5, 100, 59], [314.5, 696.5, 61, 27], [273.0, 439.5, 52, 15], [294.0, 82.0, 62, 20], [305.5, 589.5, 53, 57], [301.0, 765.5, 44, 63], [472.0, 72.5, 128, 145], [268.5, 554.5, 31, 37], [257.0, 486.5, 122, 79]], 'flows': [[-5.733068980962363, 2.024237907992882], [-5.3648367604237, 2.2435692601071913], [2.055848508418741, 0.6098592599000274], [-0.5850078185758979, 0.6965595090011666], [-2.2539090923234526, 1.072113411099303], [-0.038836167147233085, -0.00015339190873252703], [4.08066463470459, 1.3703444004058838], [-12.257625272331154, 7.92592714169001], [-0.17783876947220753, 0.03886195855100325], [0.5781293801700368, 0.11551170797909008], [-0.11180121940242295, 0.20458332585141883]]}, {'bb': [[301.0, 58.0, 86, 28], [306.0, 187.0, 104, 56], [316.0, 697.5, 58, 25], [273.0, 440.0, 50, 14], [231.5, 85.5, 31, 21], [305.5, 590.5, 53, 57], [302.0, 769.0, 42, 68], [473.0, 67.5, 126, 135], [268.0, 555.0, 30, 38], [272.5, 663.0, 19, 32], [257.0, 487.5, 122, 77]], 'flows': [[2.5954557849514868, 0.12171340757800687], [-4.9907044941434195, -0.2070159912109375], [3.991026300683244, 0.044902630604296175], [-4.825602111047702, 0.36000310864196317], [-10.810843857993817, 5.605234289741724], [0.3867301729382076, -0.6415272146849006], [4.8639780357547595, 1.2331510874107547], [0.40602407767730636, -0.42332669889896885], [1.4409500513321314, -0.12109181004711705], [0.6613040838902762, -0.37812147129296414]]}, {'bb': [[313.0, 704.5, 68, 31], [304.0, 48.5, 88, 37], [287.5, 862.0, 35, 16], [308.0, 183.5, 98, 67], [479.0, 62.0, 120, 124], [305.5, 591.5, 51, 59], [303.5, 774.0, 45, 68], [268.0, 554.5, 30, 35], [273.0, 664.5, 20, 33], [257.5, 487.5, 119, 77]], 'flows': [[-6.464448997442671, 1.7497074483967514], [2.0814619902208786, 0.6094562195366485], [2.040392927294783, 0.5509826138488247], [-5.745829846683595, 2.0939058472318406], [-5.344378630593804, 1.5420044785727733], [-0.6079513843242939, 0.7979023273174579], [4.517707581553117, 1.8007499007650116], [-0.07489657620771216, 0.25295544545584864], [-12.460594991284598, 7.185780853845341], [-0.21013362948018366, 0.4246791004371399], [0.8149030233166882, 0.6061479391510953], [-0.019526248703354513, 0.7247387582805299]]}, {'bb': [[306.5, 42.5, 85, 29], [312.5, 707.0, 67, 30], [286.5, 862.0, 35, 20], [305.5, 176.5, 105, 59], [287.0, 54.0, 68, 20], [273.0, 437.5, 48, 13], [304.0, 780.0, 44, 70], [305.0, 591.5, 54, 55], [483.5, 58.0, 111, 116], [267.0, 555.0, 30, 36], [271.5, 665.5, 21, 33], [256.0, 489.0, 122, 80]], 'flows': [[-5.047356437576173, -0.2128670998712199], [2.676312341479835, -0.944163962691007], [-5.380297268733422, -0.4405163023769065], [-4.32649422704646, -0.970225106298396], [0.2446359790929545, -1.3447363949111892], [2.5474445225842577, -0.9275966813539889], [0.5847111663255304, -1.6171009021491582], [5.1705333106682945, 0.1270636360344624], [-11.196419956812056, 6.745705613666994], [0.5386385602939173, -1.4422885614492529], [1.4703757926209333, -1.1481397097513555], [0.8483893502004225, -1.4514294125520955]]}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rVnPJpAaER1Q","executionInfo":{"status":"ok","timestamp":1617308090596,"user_tz":240,"elapsed":259,"user":{"displayName":"Heming Huang","photoUrl":"","userId":"00439147638198051252"}}},"source":["import json\n","# json.dump(load_optical_res, open('/content/drive/MyDrive/EECS 568/Final Projects/Mask_RCNN_stuff/optical_res.json', 'wb'))\n","with open('/content/drive/MyDrive/Mask_RCNN_stuff/optical_res.json', 'w') as fout:\n","    json.dump(results, fout)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L-iY8eh2_3CP"},"source":["##Run this just to load the results.\n"]},{"cell_type":"code","metadata":{"id":"t0eJJu8vKgZE"},"source":["# load with pickle\n","import pickle\n","# file_names = next(os.walk(IMAGE_DIR))[2]\n","# file_names.sort()\n","\n","PICKLE_DIR = os.path.join(ROOT_DIR, \"optical_flow_16-11.pkl\")\n","\n","load_optical_res = pickle.load(open(PICKLE_DIR, 'rb'))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8HP3qC0O3R3","outputId":"173997e2-c1f8-4380-c56c-e9e0d90f9698"},"source":["print(type(load_optical_res[0]['bb'][0][0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'numpy.float64'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"id":"5ylv-P9gSb9q","outputId":"b85ce53f-46a3-4435-e552-37a4c0afeade"},"source":["print(load_optical_res[0]['bb'][0])"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-ca8f8a684b79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_optical_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'load_optical_res' is not defined"]}]},{"cell_type":"code","metadata":{"id":"MtRr-MXQkjKL"},"source":["for dict in load_optical_res:\n","  dict[]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gmOV39PQW8X5"},"source":["import json\n","# json.dump(load_optical_res, open('/content/drive/MyDrive/EECS 568/Final Projects/Mask_RCNN_stuff/optical_res.json', 'wb'))\n","with open('/content/drive/MyDrive/EECS 568/Final Projects/Mask_RCNN_stuff/optical_res.json', 'w') as fout:\n","    json.dump(load_optical_res[0]['bb'][0], fout)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q003fR2Edx0Y"},"source":["# Write in CSV\n"]},{"cell_type":"code","metadata":{"id":"O_OJXZUWYKlC"},"source":["import pandas as pd \n","\n","scores_data = load_res[0]['scores']\n","print(scores_data.shape)\n","print(scores_data)\n","pd.DataFrame(scores_data).to_csv(\"/content/drive/MyDrive/EECS 568/Final Projects/Mask_RCNN_stuff/csv_results/scores.csv\",index=False, header=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OByTCAzacN4g"},"source":["rois_data = load_res[0]['rois']\n","print(rois_data.shape)\n","print(rois_data)\n","pd.DataFrame(rois_data).to_csv(\"/content/drive/MyDrive/EECS 568/Final Projects/Mask_RCNN_stuff/csv_results/rois.csv\",index=False, header=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7xGB8XIegRE"},"source":["class_ids_data = load_res[0]['class_ids']\n","print(class_ids_data.shape)\n","print(class_ids_data)\n","pd.DataFrame(class_ids_data).to_csv(\"/content/drive/MyDrive/EECS 568/Final Projects/Mask_RCNN_stuff/csv_results/class_ids.csv\",index=False, header=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3RzZhcAcIHk"},"source":["masks_data = load_res[0]['masks']\n","print(masks_data.shape)\n","print(masks_data)\n","pd.DataFrame(masks_data).to_csv(\"/content/drive/MyDrive/EECS 568/Final Projects/Mask_RCNN_stuff/masks.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VgR6jOFErQG2"},"source":["for i in range(0, 1):\n","    image = scipy.misc.imread(os.path.join(IMAGE_DIR, file_names[i]))\n","    visualize.display_instances(image, load_res[i]['rois'], load_res[i]['masks'], load_res[i]['class_ids'], \n","                                class_names, load_res[i]['scores'])"],"execution_count":null,"outputs":[]}]}